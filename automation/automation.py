import os
from typing import List

import pandas as pd

YEAR_PATTERN = '![year](https://img.shields.io/badge/year-{}-green?style=flat)'
AUTH_PATTERN = '![auth](https://img.shields.io/badge/author-{}-blue?style=flat)'
FILE_PATTERN = '[![file](https://img.shields.io/badge/File-red?style=flat)]({})'
NOTE_PATTERN = '[![note](https://img.shields.io/badge/{}-purple?style=flat)]({})'
TAG_PATTERN = '![tags](https://img.shields.io/badge/tag-{}-lightgrey?style=flat)'


def update_database(file_path: str, note_path: str, data_path: str, topics: List[str],
                    columns: List[str]) -> pd.DataFrame:
    database = pd.read_csv(data_path)
    notes = os.listdir(note_path)
    paper_df = pd.DataFrame(columns=columns)

    for topic in topics:
        paper_files = [f for f in os.listdir(file_path + topic) if f.endswith('.pdf')]
        paper_files.sort()

        for paper_file in paper_files:
            file_name = paper_file[:-4]
            year = file_name[1:5]
            author = file_name.split(']')[0].split(' ')[-1]
            title = file_name.split('] ')[1]
            paper_path = os.path.join(file_path, topic, paper_file)
            tag = file_name.split('@')[-1].split(' ')[0] if '@' in file_name else ''
            note_file_path = ''
            for note in notes:
                if note.startswith(file_name):
                    note_file_path = os.path.join(note_path, note)
            row = pd.DataFrame([[topic, year, author, title, paper_path, note_file_path, tag, '']], columns=columns)
            if row['title'].values not in database['title'].values:
                paper_df = pd.concat([paper_df, row], ignore_index=True)
                print(row)
    print(f'extracted {len(paper_df)} papers')

    database = pd.concat([database, paper_df], ignore_index=True)
    database = database.sort_values('paper', ignore_index=True)
    database.to_csv(data_path, index=False)

    return database


def load_table_entries(path: str, topic: str) -> List[str]:
    df = pd.read_csv(path, dtype=str)
    df = df[df['topic'] == topic]
    df.columns = df.columns.str.strip()
    return [format_entry(row) for _, row in df.iterrows()]


def format_entry(entry: pd.Series) -> str:
    entry_str = '- [x] ' if isinstance(entry.loc['status'], str) else '- [ ] '
    title = entry.loc['title'].replace('_', ': ')
    year = YEAR_PATTERN.format(entry.loc['year'])
    author = AUTH_PATTERN.format(entry.loc['author'].replace('-', '_'))
    paper = FILE_PATTERN.format(entry.loc['paper'].replace(' ', '%20'))
    entry_str += f'{title}\n  - {year}\n    {author}\n    {paper}'

    note = entry.loc['note'].replace(' ', '%20') if isinstance(entry.loc['note'], str) else ''
    note = NOTE_PATTERN.format('Note', note) if note else ''
    tags = entry.loc['tags'] if isinstance(entry.loc['tags'], str) else ''
    tags = TAG_PATTERN.format(tags) if tags else ''
    if note and tags:
        entry_str += f'\n    {note}\n    {tags}'
    elif note and not tags:
        entry_str += f'\n    {note}'
    elif not note and tags:
        entry_str += f'\n    {tags}'

    return entry_str


def read_lines_from_file(path: str) -> List[str]:
    '''Reads lines from file and strips trailing whitespaces.'''
    with open(path) as file:
        return [line.rstrip() for line in file]


def inject_markdown_table_into_readme(readme_lines: List[str], table_lines: List[str], topic: str) -> List[str]:
    '''Injects markdown table into readme.'''
    lines_with_token_indexes = search_lines_with_token(lines=readme_lines, token=tokens.get(topic))
    if len(lines_with_token_indexes) != 2:
        raise Exception(f'Please inject two {tokens.get(topic)} '
                        f'tokens to signal start and end of autogenerated table.')

    [table_start_line_index, table_end_line_index] = lines_with_token_indexes
    return readme_lines[:table_start_line_index + 1] + table_lines + readme_lines[table_end_line_index:]


def search_lines_with_token(lines: List[str], token: str) -> List[int]:
    '''Searches for lines with token. '''
    result = []
    for line_index, line in enumerate(lines):
        if token in line:
            result.append(line_index)
    return result


def save_lines_to_file(path: str, lines: List[str]) -> None:
    '''Saves lines to file. '''
    with open(path, 'w') as f:
        for line in lines:
            f.write('%s\n' % line)


if __name__ == '__main__':
    file_path = './files/'
    note_path = './notes/'
    data_path = './automation/database.csv'
    readme_path = 'README.md'

    columns = ['topic', 'year', 'author', 'title', 'paper', 'note', 'tags', 'status']
    topics = [f for f in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, f))]
    topics.sort()
    print(topics)
    tokens = {}
    for topic in topics:
        tokens[topic] = f'<!-- AUTOGENERATED_{topic} -->'

    update_database(file_path=file_path, note_path=note_path, data_path=data_path, topics=topics, columns=columns)

    for topic in topics:
        table_lines = load_table_entries(path=data_path, topic=topic)
        readme_lines = read_lines_from_file(path=readme_path)
        readme_lines = inject_markdown_table_into_readme(readme_lines=readme_lines,
                                                         table_lines=table_lines,
                                                         topic=topic)
        save_lines_to_file(path=readme_path, lines=readme_lines)
